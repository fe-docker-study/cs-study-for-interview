# Apache Kafka란?
**아파치 카프카**는 빠르고 확장 가능한 작업을 위해 데이터 피드의 분산 스트리밍, 파이프 라이닝 및 재생을 위한 `실시간 스트리밍 데이터를 처리하기 위한 목적으로 설계`된 오픈 소스 분산형 게시-구독 메시징 플랫폼이다.

## 메시징 시스템(Messaging System)
메시징 시스템은 Kafka, RabbitMQ, ActiveMQ, AWS SQS, Java JMS 등이 있다. `MSA` 같은 시스템 같은 경우에 시스템 간 호출이 많아 서비스 결합도를 낮추기 위해 비동기 요청, 성능, 안정성 등을 위해 메시징 시스템을 사용하곤 한다.
그렇다면 메시징 시스템이란 도대체 뭘까? **보통은 로그 데이터, 이벤트 메시지 등을 API로 호출할 때 보내는 데이터들을 처리하는 시스템**이라고 생각하면 된다.

### 자동 메일 발송 시스템
![](https://velog.velcdn.com/images/shinmj1207/post/d453c2e6-c13d-49d9-ad75-87f7ad664e2a/image.png)

* **MemberService** : 회원 가입 시 이메일을 발송
* **OrderService** : 주문 완료 시 이메일을 발송
* **MailServcie** : 실제 메일을 발송하는 서비

1. MemberService에서 회원가입 후, OrderService에서 주문완료 이벤트가 발생하면 
2. Messaging Client로 메일 전송에 필요한 데이터를 API로 호출
3. Messaging Client에서 MOM을 구현한 소프트웨어(Kafka)로 메세지 생산
4. MailService에서 메세지가 존재하는지 구독하고있다가 메세지가 존재하면 메세지 소비
5. MailService에서 API 정보들을 통해 User에게 메일 발송
 
이런 메세징 시스템들은 `‘Publish/Subscribe’` 형태의 통신을 하며 메세지를 보내고(Publish) 받는(Subscribe)다. 대부분의 발행/구독 시스템은 `메세지 큐`나 `프로세스 간 통신 채널`을 갖는 형태로 만들어진다.


### 왜 메세징 시스템을 써야할까?
그렇다면 왜 메세징 시스템이 필요할까?
만약 아래 그림같이 프론트엔드 서버와 백엔드 서버로부터 전체 리소스 사용 데이터를 수집하는 메트릭 서버가 있다고 해보자. 서비스 배포 초기에는 위와 같이 간단하게 구성할 수 있을 것이다.
![](https://velog.velcdn.com/images/shinmj1207/post/7e88a182-ff7c-4cff-8d60-c908f40bb004/image.png)


하지만, 우리는 운영하면서 데이터베이스 서버, 채팅 서버, 인증 서버등의 추가와 분리의 필요성을 느끼게 되었고 이를 아래와 같이 재구성하였다.

![](https://velog.velcdn.com/images/shinmj1207/post/aef769b5-fb34-4587-830d-d0914cabc15a/image.png)

서비스 인스턴스가 다음과 같이 늘어나고 추가적인 로그 수집 서버나 모니터링 서버가 추가되면 복잡해지게 된다. 이렇게 된 이유는 무엇일까?
**각 인스턴스 서버(프론트엔드, 백엔드, 채팅, 인증 서버 등등, 이하 통칭 publisher)와 각 메트릭 서버(이하 통칭 consumer)들이 직접 연결된 구조**이기 때문이다. 1:1의 관계기 때문에 복잡도가 증가하게 되는 것이다.
이는 한 곳에서 수정이 일어나면 다른 곳에 영향을 줄 수 있다는 의미가 된다. 
결국은 의존성 문젠데 이는 다른 아키텍처와 마찬가지고 결합도를 줄이는 느슨한 구조로 변경해야 한다.
이를 메세징 시스템을 통해 아래와 바꿔보자.
![](https://velog.velcdn.com/images/shinmj1207/post/675f78ec-b1b6-477f-8649-1b352787f42d/image.png)

만약 메트릭 발행/구독 서버(Kafka와 같은)를 추가하게 되면 
1. publisher는 consumer의 정보를 알 필요가 없다.(직접 연결 없어짐) 서로의 변경의 영향을 받지 않게된다.
2. publisher는 단순하게 발행/구독 시스템에 전송하면 consumer는 이 메세지를 읽어가기만 하면 된다.
3. 서버가 추가되어도 서로에게 영향을 끼치지 않기 때문에 새로운 서버를 추가하거나 기존 서버를 변경하는데 수월해지고, 수평적인 확장이 가능해진다.

## 왜 Kafka인가?
그렇다면 왜 Kafka를 써야 하는가? 

### 다중 프로듀서, 다중 컨슈머
메세징 시스템의 publisher 역할을 하는 것이 카프카의 `producer`이다. 
카프카는 하나의 토픽에 여러 프로듀서 또는 컨슈머들이 접근 가능한 구조로 되어있다. 즉, **하나의 프로듀서가 하나의 토픽에만 메세지를 보내는 것이 아니라 하나 또는 하나 이상의 토픽으로 메세지를 보낼 수 있다.(컨슈머도)** 멀티 프로듀서와 멀티 컨슈머를 구성할 수 있기 때문에 카프카는 중앙 집중형 구조를 구성할 수 있다.
또한, 여러 클라이언트가 많은 토픽(메세지 저장소)를 사용하거나 같은 토픽을 사용해도 카프카는 무리없이 처리할 수 있다. 여러 프로듀서로부터 데이터를 수집하고 일관성을 유지하는데 이상적인 구조를 가지고 있다.
구독자 역할을 하는 것이 카프카의 consumer이다. 카프카는 상호 간섭없이 어떤 메세지도 읽을 수 있게 지원한다. 다른 메세징 시스템의 경우엔 한 구독자 클라이언트가 특정 메세지를 소비하면 다른 구독자 클라이언트에서는 그 메세지를 사용할 수 없다. 하지만 카프카 컨슈머는 컨슈머 그룹이란 개념을 사용하여 각각의 컨슈머가 메세지를 관리할 수 있다. 

### 디스크에 기반의 보존
카프카가 기존의 메세징 시스템과 가장 다른 특징 중 하나는 `디스크에 메세지를 저장하고 유지`할 수 있다는 것이다. 일반적인 메세징 시스템들은 컨슈머가 메세지를 읽어가면 큐에서 바로 메세지를 삭제한다. 하지만, 카프카는 컨슈머가 메세지를 읽어가더라도 정해져 있는 보관 주기 동안 디스크에 메세지를 저장해둔다. 
만약, 트래픽이 일시적으로 폭주해 컨슈머의 처리가 늦어지더라도 카프카의 디스크에 안전하게 보관되어 있기 때문에 컨슈머는 손실 없이 메세지를 가져갈 수 있다. 또한, 컨슈머에 버그가 있어 오류가 발생했다면, 컨슈머를 잠시 중단하고 버그를 찾아 해결한 후 컨슈머를 다시 실행할 수 있다.

### 확장성
카프카는 확장이 매우 용이하도록 설계되어있다. 확장 작업은 카프카 서비스의 **중단 없이** 온라인 상태에서 작업이 가능하다. 

### 분산 처리
Scale-out이 가능하여 시스템 확장이 용이하며 어떤 하나 혹은 몇 개의 서버가 다운되도 서비스 자체가 중단될 일 없이 시스템 운용이 가능하다. 또한, 카프카는 `파티션`이라는 개념을 도입하여 여러 개의 파티션을 서버에 분산시켜 처리할 수 있다. (빠른 메세지 처리가 가능)

### 페이지 캐시
잔여 메모리를 이용해 디스크 Read/Write를 하지 않고, 페이지 캐시를 통한 Read/Write를 인해 처리 속도가 매우 빠르다.
![](https://velog.velcdn.com/images/shinmj1207/post/b624d189-526e-4b92-bac6-954b9e64cd3b/image.png)

## Kafka 용어 정리
* **Broker** : 카프카 애플리케이션이 설치되어 있는 서버 또는 노드
* **Topic** : 프로듀서와 컨슈머들이 카프카로 보낸 자신들의 메세지를 구분하기 위한 네임으로 사용
* **Partition** : 병렬처리가 가능하도록 토픽을 나눌 수 있고, 많은 양의 메세지 처리를 위해 파티션의 수를 늘려줄 수 있다.
* **Producer** : 메세지를 생산하여 브로커의 토픽 이름으로 보내는 서버 또는 애플리케이션 등을 말한다.
* **Consumer** : 브로커의 토픽 이름으로 저장된 메세지를 가져가는 서버 또는 애플리케이션 등을 마랗ㄴ다.


## 파티션 읽기/쓰기 프로세스
![](https://velog.velcdn.com/images/shinmj1207/post/89bb1d04-13ed-4daa-832d-e41b8b499645/image.png)

**아파치 카프카에서의 쓰기, 읽기 연산은 카프카 클러스터 내의 리더 파티션들에게만 적용**된다. 하늘색 표시의 리터 파티션에게 프로듀서들이 쓰기 연산을 진행하며 이렇게 업데이트 된 데이터는 각 파티션들의 복제본들(Replica)들에게 복사된다.

### Producer의 쓰기 연산
![](https://velog.velcdn.com/images/shinmj1207/post/9115a3b2-4fae-4577-9d4f-01557cdeeaad/image.png)

카프카는 데이터를 순차적으로 디스크에 저장하는 특징을 가진다. 따라서 프로듀서는 저장된 데이터 뒤에 붙이는 append 형식으로 write 연산을 진행하게 된다. 이 때 파티션들은 각각의 데이터들의 순차적인 집합인 **오프셋(offset)**으로 구성되어있다.
![](https://velog.velcdn.com/images/shinmj1207/post/60088623-a29c-447f-a093-f8a57d390877/image.png)

컨슈머그룹의 각 컨슈머들은 파티션의 오프셋을 기준으로 데이터를 순차적으로 처리하게 된다. (먼저 들어온 순서부터) 이 때, 컨슈머들은 컨슈머 그룹으로 나뉘어서 데이터를 분산처리하고 같은 컨슈머 그룹 내에 있는 컨슈머끼리 같은 파티션의 데이터를 처리할 수 없다.
파티션에 저장되어있는 데이터들은 순차적으로 데이터가 저장되어 있으며 이 데이터들은 설정값에 따라 데이터를 디스크에 보관하게 된다.

![](https://velog.velcdn.com/images/shinmj1207/post/e02641f1-3524-4694-8303-1fe969a2b73a/image.png)
위 그림은 컨슈머 그룹 단위로 그룹 내 컨슈머들이 각각의 파티션의 데이터를 처리하는 모습을 나타낸 것이다.

만일 컨슈머와 파티션의 개수가 같다면 컨슈머는 각 파티션을 1:1로 맡게 된다.`(첫 번째 경우)` 만일 컨슈머 그룹 안의 컨슈머의 개수가 파티션의 개수보다 적을 경우 컨슈머 중 하나가 남는 파티션의 데이터를 처리하게 된다. `(두 번째 경우)` 만약 컨슈머의 개수가 파티션의 개수보다 많을 경우는 남는 컨슈머가 파티션 개수가 많아질 때까지 대기한다.`(세 번째 경우)`
